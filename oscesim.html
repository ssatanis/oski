<!DOCTYPE html>
<!-- This site was created in Webflow. https://webflow.com --><!-- Last Published: Fri Jun 13 2025 13:52:06 GMT+0000 (Coordinated Universal Time) --><html data-wf-domain="tenet-template.webflow.io" data-wf-page="683d91777124b040c4a5b5cd" data-wf-site="683d91777124b040c4a5b5db" lang="en"><head><meta charset="utf-8"><title>Oski - Simulation</title><meta content="Experience Oski's AI-powered medical assessment simulation platform." name="description"><meta content="Oski - Simulation" property="og:title"><meta content="Experience Oski's AI-powered medical assessment simulation platform." property="og:description"><meta content="Oski - Simulation" property="twitter:title"><meta content="Experience Oski's AI-powered medical assessment simulation platform." property="twitter:description"><meta property="og:type" content="website"><meta content="summary_large_image" name="twitter:card"><meta content="width=device-width, initial-scale=1" name="viewport"><meta content="Webflow" name="generator"><link href="https://cdn.prod.website-files.com/683d91777124b040c4a5b5db/css/tenet-template.webflow.shared.40365d26e.css" rel="stylesheet" type="text/css"><link href="https://fonts.googleapis.com" rel="preconnect"><link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="anonymous"><script src="js/1.6.26-webfont.js" type="text/javascript"></script><script type="text/javascript">WebFont.load({  google: {    families: ["Geist:100,200,300,regular,500,600,700,800,900","Prata:regular"]  }});</script><script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>

<!-- Dynamic Favicon based on theme -->
<script>
function setFavicon() {
  const isDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
  const favicon = document.querySelector('link[rel="shortcut icon"]') || document.createElement('link');
  favicon.rel = 'shortcut icon';
  favicon.type = 'image/svg+xml';
  favicon.href = isDarkMode ? 'favicons/White.svg' : 'favicons/Black.svg';
  if (!document.querySelector('link[rel="shortcut icon"]')) {
    document.head.appendChild(favicon);
  }
}
setFavicon();
window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', setFavicon);
</script>

<link href="favicons/683d91777124b040c4a5b5db-683d91777124b040c4a5b63e_logo.png" rel="apple-touch-icon">
<style>
/* Hide Webflow badge */
.w-webflow-badge {
  display: none !important;
}

/* Seamless white gradient background throughout the page */
body {
  background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%) !important;
}

.hero, .section {
  background: transparent !important;
}

/* Remove simulation container styling for seamless integration */
.simulation-container {
  width: 100%;
  max-width: none;
  margin: 0;
  padding: 0;
  background: transparent;
  border-radius: 0;
  box-shadow: none;
  position: relative;
  overflow: visible;
}

.simulation-container::before {
  display: none;
}

/* OSCE Video Grader Specific Styles */
.osce-container {
    background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
    border-radius: 20px;
    padding: 2rem;
    margin: 2rem 0;
    box-shadow: 0 20px 40px rgba(0,0,0,0.1);
}

.osce-grid {
    display: grid;
    grid-template-columns: 1fr 2fr;
    gap: 2rem;
    align-items: start;
}

.config-panel {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    backdrop-filter: blur(10px);
    border-radius: 15px;
    padding: 1.5rem;
    border: 1px solid rgba(255,255,255,0.2);
}

.workflow-panel {
    background: rgba(255,255,255,0.95);
    border-radius: 15px;
    padding: 1.5rem;
    color: #333;
}

.input-group {
    margin-bottom: 1.5rem;
}

.input-label {
    display: block;
    color: white;
    font-weight: 600;
    margin-bottom: 0.5rem;
    font-size: 0.9rem;
}

.input-field, .select-field {
    width: 100%;
    padding: 0.75rem;
    border: 1px solid rgba(255,255,255,0.3);
    border-radius: 8px;
    background: rgba(255,255,255,0.1);
    color: white;
    font-size: 0.9rem;
    box-sizing: border-box;
}

.input-field::placeholder {
    color: rgba(255,255,255,0.7);
}

.btn-primary {
    background: linear-gradient(135deg, #4CAF50, #81C784);
    color: white;
    border: none;
    padding: 1rem 2rem;
    border-radius: 8px;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s ease;
    width: 100%;
    margin-top: 1rem;
}

.btn-primary:hover {
    transform: translateY(-2px);
    box-shadow: 0 10px 20px rgba(0,0,0,0.2);
}

.btn-secondary {
    background: rgba(255,255,255,0.2);
    color: white;
    border: 1px solid rgba(255,255,255,0.3);
    padding: 0.75rem 1.5rem;
    border-radius: 8px;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s ease;
    width: 100%;
    margin-top: 0.5rem;
}

.workflow-step {
    border: 2px solid #e0e0e0;
    border-radius: 10px;
    padding: 1rem;
    margin: 0.75rem 0;
    background: #f8f9fa;
    transition: all 0.3s ease;
}

.workflow-step.active {
    border-color: #4CAF50;
    background: #f0f8f0;
    transform: translateX(5px);
}

.workflow-step.completed {
    border-color: #2196F3;
    background: #e3f2fd;
}

.step-title {
    font-weight: 700;
    margin-bottom: 0.5rem;
    color: #333;
}

.step-description {
    font-size: 0.85rem;
    color: #666;
    line-height: 1.4;
}

.grade-display {
    text-align: center;
    padding: 2rem;
    border-radius: 15px;
    margin: 1rem 0;
    font-size: 3rem;
    font-weight: bold;
}

.grade-4 { background: linear-gradient(135deg, #4CAF50, #81C784); color: white; }
.grade-3 { background: linear-gradient(135deg, #FFC107, #FFD54F); color: #333; }
.grade-2 { background: linear-gradient(135deg, #FF9800, #FFB74D); color: white; }
.grade-1 { background: linear-gradient(135deg, #F44336, #EF5350); color: white; }
.grade-0 { background: linear-gradient(135deg, #9E9E9E, #BDBDBD); color: white; }

.evidence-card {
    background: #f0f2f6;
    border-left: 4px solid #4CAF50;
    padding: 1rem;
    margin: 0.75rem 0;
    border-radius: 8px;
}

.video-upload-area {
    border: 2px dashed rgba(255,255,255,0.5);
    border-radius: 10px;
    padding: 2rem;
    text-align: center;
    cursor: pointer;
    transition: all 0.3s ease;
    background: rgba(255,255,255,0.05);
}

.file-upload-area {
    border: 2px dashed rgba(255,255,255,0.5);
    border-radius: 10px;
    padding: 2rem;
    text-align: center;
    cursor: pointer;
    transition: all 0.3s ease;
    background: rgba(255,255,255,0.05);
}

.file-upload-area:hover {
    border-color: rgba(255,255,255,0.8);
    background: rgba(255,255,255,0.1);
    transform: translateY(-2px);
}

.video-upload-area:hover {
    border-color: rgba(255,255,255,0.8);
    background: rgba(255,255,255,0.1);
}

.progress-bar {
    width: 100%;
    height: 8px;
    background: #e0e0e0;
    border-radius: 4px;
    overflow: hidden;
    margin-bottom: 1rem;
}

.progress-fill {
    height: 100%;
    background: linear-gradient(135deg, #4CAF50, #81C784);
    width: 0%;
    transition: width 0.3s ease;
}

@media (max-width: 768px) {
    .osce-grid {
        grid-template-columns: 1fr;
        gap: 1.5rem;
    }
}

.simulation-header {
  text-align: center;
  margin-bottom: 40px;
  position: relative;
  z-index: 1;
}

.simulation-title {
  font-size: 2.5rem;
  font-weight: 700;
  color: #1f2937;
  margin-bottom: 16px;
}

.simulation-description {
  font-size: 1.2rem;
  color: #6b7280;
  max-width: 600px;
  margin: 0 auto;
  line-height: 1.6;
}

/* Ensure consistent spacing and positioning to match home page exactly */
.hero .max-w-width {
  margin-top: 80px !important; /* Reduced from 120px to bring content higher */
}

/* Make sure the top-text positioning matches home page */
.top-text {
  margin-bottom: 20px;
}

/* Ensure proper spacing between hero and simulation */
#simulation {
  padding-top: 40px !important;
}

@media (max-width: 768px) {
  .simulation-iframe {
    height: 800px;
    border-radius: 12px;
  }
  
  .simulation-title {
    font-size: 2rem;
  }
  
  .simulation-description {
    font-size: 1rem;
  }
  
  .hero .max-w-width {
    margin-top: 60px !important;
  }
}
</style>

</head><body><div class="page-wrapper">
<!-- Centralized Header -->
<div id="header-container"></div>

<section class="hero" id="hero"><div class="container"><div class="max-w-width" style="margin-top: 80px;"><div data-w-id="cc4bc4b9-3fd8-9621-1de2-e0b7a0bf1285" style="opacity:0" class="top-text">Interactive Demo</div><h1 data-w-id="6b4f9255-2b7e-e6bc-76d5-b0e49087b85c" style="opacity:0" class="display-1">Experience Oski's <span class="other-font">simulation</span> platform.</h1><div class="margin-20"><p data-w-id="b90b02c7-115c-c062-22d1-a988e276c1cf" style="opacity:0" class="p-02">Try our AI-powered medical assessment tools in real-time.</p></div><div data-w-id="4c25a1b6-df10-f474-31b4-08ca1d59a136" style="opacity:0" class="margin-30"><div class="button-flex center-mobile"><a data-w-id="808f99a7-6144-0b76-f91d-d0f0d0481c64" href="#simulation" class="button-first w-inline-block"><div class="txt-wrapper"><div style="-webkit-transform:translate3d(0, 0%, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(0, 0%, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(0, 0%, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(0, 0%, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="button-txt">Get Started</div><div style="-webkit-transform:translate3d(0, 0%, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-moz-transform:translate3d(0, 0%, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);-ms-transform:translate3d(0, 0%, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0);transform:translate3d(0, 0%, 0) scale3d(1, 1, 1) rotateX(0) rotateY(0) rotateZ(0) skew(0, 0)" class="button-txt">Get Started</div></div></a></div></div></div><img src="images/683d91777124b040c4a5b5db-683f0802c2111b8ce7b802dd_shape-1.webp" loading="lazy" width="500" sizes="(max-width: 767px) 100vw, 500px" alt="" srcset="https://cdn.prod.website-files.com/683d91777124b040c4a5b5db/683f0802c2111b8ce7b802dd_shape-1-p-500.webp 500w, https://cdn.prod.website-files.com/683d91777124b040c4a5b5db/683f0802c2111b8ce7b802dd_shape-1-p-800.webp 800w, https://cdn.prod.website-files.com/683d91777124b040c4a5b5db/683f0802c2111b8ce7b802dd_shape-1-p-1080.webp 1080w, https://cdn.prod.website-files.com/683d91777124b040c4a5b5db/683f0802c2111b8ce7b802dd_shape-1.webp 1674w" class="shape-1"></section>

<section id="simulation" style="padding: 40px 0 80px 0;">
  <div class="container">
    <!-- Simulation Header -->
    <div class="simulation-header" style="text-align: center; margin-bottom: 3rem;">
      <h2 class="simulation-title" style="font-size: 2.5rem; font-weight: 700; color: #1f2937; margin-bottom: 1rem;">üé• OSCE Video Assessment System</h2>
      <p class="simulation-description" style="font-size: 1.1rem; color: #6b7280; max-width: 600px; margin: 0 auto;">Multi-Agent Planner-Executor-Scorer-Reflector-Consensus Framework</p>
    </div>
    
    <!-- OSCE Container -->
    <div class="osce-container">
      <div class="osce-grid">
        <!-- Configuration Panel -->
        <div class="config-panel">
          <h3 style="color: white; margin-bottom: 1.5rem; font-size: 1.3rem;">‚öôÔ∏è Configuration</h3>

          <!-- Upload & Index Video -->
          <div class="input-group">
            <label class="input-label">üìπ Upload & Index Video</label>
            <div class="video-upload-area" onclick="document.getElementById('videoInput').click()">
              <input type="file" id="videoInput" accept="video/*" style="display: none;" onchange="handleVideoUpload(this)">
              <p style="color: white; margin: 0;">Click to upload OSCE video</p>
              <p style="color: rgba(255,255,255,0.7); font-size: 0.8rem; margin: 0.5rem 0 0 0;">Supports MP4, AVI, MOV, MKV formats</p>
            </div>
            <div id="videoPreview" style="margin-top: 1rem; display: none;">
              <video id="uploadedVideo" style="width: 100%; border-radius: 8px;" controls></video>
              <p id="videoName" style="color: white; margin-top: 0.5rem; font-size: 0.9rem;"></p>
              <div id="indexingStatus" style="margin-top: 0.5rem; padding: 0.5rem; background: rgba(255,255,255,0.1); border-radius: 6px; display: none;">
                <p style="color: #4CAF50; margin: 0; font-size: 0.8rem;">‚úÖ Video indexed successfully</p>
              </div>
            </div>
          </div>

          <!-- Select Video for Assessment -->
          <div class="input-group">
            <label class="input-label">üé¨ Select Video for Assessment</label>
            <select class="select-field" id="videoSelection" disabled>
              <option value="">Upload a video first...</option>
            </select>
          </div>

          <!-- YAML Rubric Upload -->
          <div class="input-group">
            <label class="input-label">üìÑ Upload YAML Rubric</label>
            <div class="file-upload-area" onclick="document.getElementById('yamlInput').click()">
              <input type="file" id="yamlInput" accept=".yaml,.yml" style="display: none;" onchange="handleYamlUpload(this)">
              <div style="color: white; text-align: center;">
                <div style="font-size: 2.5rem; margin-bottom: 1rem;">üìã</div>
                <p style="margin: 0; font-size: 1.1rem;">Upload your YAML rubric file</p>
                <p style="color: rgba(255,255,255,0.7); font-size: 0.9rem; margin: 0.5rem 0 0 0;">Generate using PromptGen tool</p>
                <p style="color: rgba(255,255,255,0.6); font-size: 0.8rem; margin: 1rem 0 0 0;">Supports .yaml and .yml files</p>
              </div>
            </div>
            <div id="yamlPreview" style="margin-top: 1rem; display: none;">
              <div id="yamlInfo" style="color: white; padding: 1rem; background: rgba(255,255,255,0.1); border-radius: 8px; margin-bottom: 1rem;"></div>
              <div id="yamlContent" style="max-height: 200px; overflow-y: auto; background: rgba(0,0,0,0.3); padding: 1rem; border-radius: 8px; font-family: monospace; font-size: 0.8rem; color: #e0e0e0; line-height: 1.4;"></div>
            </div>
          </div>

          <!-- Model Configuration -->
          <div class="input-group">
            <label class="input-label">ü§ñ Model Settings</label>
            
            <!-- CLIP Model -->
            <div style="margin-bottom: 0.75rem;">
              <label style="color: rgba(255,255,255,0.9); font-size: 0.8rem; margin-bottom: 0.25rem; display: block;">CLIP Model</label>
              <select class="select-field" id="clipModel">
                <option value="ViT-B/32">ViT-B/32</option>
                <option value="ViT-L/14">ViT-L/14</option>
                <option value="RN50x64">RN50x64</option>
                <option value="ViT-B/16">ViT-B/16</option>
              </select>
            </div>

            <!-- CLAP Model -->
            <div style="margin-bottom: 0.75rem;">
              <label style="color: rgba(255,255,255,0.9); font-size: 0.8rem; margin-bottom: 0.25rem; display: block;">CLAP Model</label>
              <select class="select-field" id="clapModel">
                <option value="CLAP-base">CLAP-base</option>
                <option value="CLAP-large">CLAP-large</option>
                <option value="CLAP-630k">CLAP-630k</option>
              </select>
            </div>

            <!-- LLM Model -->
            <div>
              <label style="color: rgba(255,255,255,0.9); font-size: 0.8rem; margin-bottom: 0.25rem; display: block;">LLM Model</label>
              <select class="select-field" id="llmModel">
                <option value="GPT-4">GPT-4</option>
                <option value="GPT-4-turbo">GPT-4-turbo</option>
                <option value="Claude-3-Opus">Claude-3-Opus</option>
                <option value="Claude-3-Sonnet">Claude-3-Sonnet</option>
                <option value="Gemini-Pro">Gemini-Pro</option>
              </select>
            </div>
          </div>

          <!-- Processing Parameters -->
          <div class="input-group">
            <label class="input-label">‚ö° Processing Parameters</label>
            
            <!-- Top-K Keyframes -->
            <div style="margin-bottom: 1rem;">
              <label style="color: rgba(255,255,255,0.8); font-size: 0.8rem;">Top-K Keyframes: <span id="keyframeValue">5</span></label>
              <input type="range" id="topKKeyframes" min="1" max="20" value="5" style="width: 100%; margin-top: 0.5rem;" oninput="document.getElementById('keyframeValue').textContent = this.value">
            </div>

            <!-- Top-K Audio Segments -->
            <div style="margin-bottom: 1rem;">
              <label style="color: rgba(255,255,255,0.8); font-size: 0.8rem;">Top-K Audio Segments: <span id="audioValue">3</span></label>
              <input type="range" id="topKAudio" min="1" max="15" value="3" style="width: 100%; margin-top: 0.5rem;" oninput="document.getElementById('audioValue').textContent = this.value">
            </div>

            <!-- Confidence Threshold -->
            <div style="margin-bottom: 1rem;">
              <label style="color: rgba(255,255,255,0.8); font-size: 0.8rem;">Confidence Threshold: <span id="confidenceValue">0.7</span></label>
              <input type="range" id="confidenceThreshold" min="0" max="1" step="0.1" value="0.7" style="width: 100%; margin-top: 0.5rem;" oninput="document.getElementById('confidenceValue').textContent = this.value">
            </div>

            <!-- Temperature -->
            <div style="margin-bottom: 1rem;">
              <label style="color: rgba(255,255,255,0.8); font-size: 0.8rem;">Temperature: <span id="temperatureValue">0.3</span></label>
              <input type="range" id="temperature" min="0" max="1" step="0.1" value="0.3" style="width: 100%; margin-top: 0.5rem;" oninput="document.getElementById('temperatureValue').textContent = this.value">
            </div>

            <!-- Max Tokens -->
            <div>
              <label style="color: rgba(255,255,255,0.8); font-size: 0.8rem;">Max Tokens: <span id="maxTokensValue">1000</span></label>
              <input type="range" id="maxTokens" min="100" max="4000" step="100" value="1000" style="width: 100%; margin-top: 0.5rem;" oninput="document.getElementById('maxTokensValue').textContent = this.value">
            </div>
          </div>

          <!-- Action Buttons -->
          <button class="btn-primary" onclick="startAssessment()">üöÄ Start Assessment</button>
          <button class="btn-secondary" onclick="resetAssessment()">üîÑ Reset</button>
        </div>

        <!-- Workflow Panel -->
        <div class="workflow-panel">
          <h3 style="color: #333; margin-bottom: 1.5rem; font-size: 1.3rem;">üîÑ Assessment Workflow</h3>

          <!-- Progress Bar -->
          <div id="progressContainer" style="display: none;">
            <div class="progress-bar">
              <div class="progress-fill" id="progressFill"></div>
            </div>
            <p id="progressText" style="text-align: center; color: #666; margin: 0.5rem 0;">Ready to begin assessment...</p>
          </div>

          <!-- Workflow Steps -->
          <div id="step-planner" class="workflow-step">
            <div class="step-title">üéØ 1. Planner Agent</div>
            <div class="step-description">Analyzes video content and creates assessment strategy</div>
          </div>

          <div id="step-executor" class="workflow-step">
            <div class="step-title">‚ö° 2. Executor Agent</div>  
            <div class="step-description">Processes video and audio using multimodal AI models</div>
          </div>

          <div id="step-scorer" class="workflow-step">
            <div class="step-title">üìä 3. Scorer Agent</div>
            <div class="step-description">Evaluates performance against rubric criteria</div>
          </div>

          <div id="step-reflector" class="workflow-step">
            <div class="step-title">ü§î 4. Reflector Agent</div>
            <div class="step-description">Reviews and validates assessment accuracy</div>
          </div>

          <div id="step-consensus" class="workflow-step">
            <div class="step-title">ü§ù 5. Consensus Agent</div>
            <div class="step-description">Finalizes grade and generates detailed feedback</div>
          </div>

          <!-- Results Container -->
          <div id="resultsContainer" style="display: none; margin-top: 2rem;">
            <div id="gradeDisplay" class="grade-display">
              <div id="gradeValue">0/5</div>
            </div>
            
            <div class="evidence-card">
              <h4 style="margin-bottom: 0.5rem; color: #333;">üìã Assessment Rationale</h4>
              <p id="rationale" style="margin: 0; color: #555; line-height: 1.5;">Assessment results will appear here...</p>
            </div>
            
            <div class="evidence-card">
              <h4 style="margin-bottom: 0.5rem; color: #333;">üîä Audio Evidence</h4>
              <p id="audioEvidence" style="margin: 0; color: #555; line-height: 1.5;">Audio analysis results...</p>
            </div>
            
            <div class="evidence-card">
              <h4 style="margin-bottom: 0.5rem; color: #333;">üìπ Video Evidence</h4>
              <p id="videoEvidence" style="margin: 0; color: #555; line-height: 1.5;">Video analysis results...</p>
            </div>
          </div>
        </div>
      </div>
    </div>
    
</section>

<!-- Centralized Footer -->
<div id="footer-container"></div>

</div>

<!-- Load centralized header and footer -->
<script src="js/header.js"></script>
<script src="js/footer.js"></script>

<!-- OSCE Video Assessment System JavaScript -->
<script>
// Global variables
let uploadedVideoFile = null;
let uploadedYamlFile = null;
let yamlContent = null;
let assessmentInProgress = false;
let indexedVideoId = null;

// API Configuration
const API_BASE_URL = 'http://localhost:8001/api/v1';

// Video upload handling
async function handleVideoUpload(input) {
    const file = input.files[0];
    if (file) {
        uploadedVideoFile = file;
        const videoPreview = document.getElementById('videoPreview');
        const uploadedVideo = document.getElementById('uploadedVideo');
        const videoName = document.getElementById('videoName');
        const indexingStatus = document.getElementById('indexingStatus');
        const videoSelection = document.getElementById('videoSelection');
        
        // Create URL for video preview
        const videoURL = URL.createObjectURL(file);
        uploadedVideo.src = videoURL;
        videoName.textContent = `üìπ ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`;
        videoPreview.style.display = 'block';
        
        // Show indexing in progress
        indexingStatus.innerHTML = '<p style="color: #FFC107; margin: 0; font-size: 0.8rem;">üîÑ Indexing video... This may take a few minutes.</p>';
        indexingStatus.style.display = 'block';
        
        try {
            // Upload and index video using real API
            const formData = new FormData();
            formData.append('video_file', file);
            formData.append('num_keyframes_to_extract', '50');
            
            const response = await fetch(`${API_BASE_URL}/index_video`, {
                method: 'POST',
                body: formData
            });
            
            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }
            
            const result = await response.json();
            indexedVideoId = result.id;
            
            // Show success
            indexingStatus.innerHTML = '<p style="color: #4CAF50; margin: 0; font-size: 0.8rem;">‚úÖ Video indexed successfully</p>';
            
            // Enable video selection dropdown and add the uploaded video
            videoSelection.disabled = false;
            videoSelection.innerHTML = `
                <option value="${indexedVideoId}">${file.name} (Indexed)</option>
            `;
            videoSelection.value = indexedVideoId;
            
        } catch (error) {
            console.error('Error indexing video:', error);
            indexingStatus.innerHTML = '<p style="color: #F44336; margin: 0; font-size: 0.8rem;">‚ùå Error indexing video. Using mock mode.</p>';
            
            // Fallback to mock mode
            setTimeout(() => {
                indexedVideoId = `mock_${Date.now()}`;
                videoSelection.disabled = false;
                videoSelection.innerHTML = `
                    <option value="${indexedVideoId}">${file.name} (Mock)</option>
                `;
                videoSelection.value = indexedVideoId;
            }, 1000);
        }
    }
}

// Real assessment using backend API
async function runRealAssessment(videoId, yamlContent, steps) {
    const progressFill = document.getElementById('progressFill');
    const progressText = document.getElementById('progressText');
    
    // Step 1: Start assessment
    progressText.textContent = 'Starting assessment...';
    progressFill.style.width = '10%';
    
    try {
        // Call the real backend API
        const response = await fetch(`${API_BASE_URL}/assess_video_yaml`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                video_id: videoId,
                yaml_content: yamlContent
            })
        });
        
        if (!response.ok) {
            throw new Error(`Assessment API error: ${response.status}`);
        }
        
        // Simulate progress through workflow steps
        for (let i = 0; i < steps.length; i++) {
            const step = steps[i];
            const stepElement = document.getElementById(`step-${step}`);
            
            // Mark current step as active
            stepElement.className = 'workflow-step active';
            progressText.textContent = `Processing ${step}...`;
            
            // Update progress
            const progress = 20 + (i * 60 / steps.length);
            progressFill.style.width = `${progress}%`;
            
            // Wait for visual feedback
            await new Promise(resolve => setTimeout(resolve, 800));
            
            // Mark as completed
            stepElement.className = 'workflow-step completed';
        }
        
        // Complete progress
        progressFill.style.width = '90%';
        progressText.textContent = 'Processing results...';
        
        // Get the assessment results
        const assessmentResult = await response.json();
        
        // Display real results
        displayRealResults(assessmentResult);
        
        progressFill.style.width = '100%';
        progressText.textContent = 'Assessment complete!';
        
    } catch (error) {
        console.error('Real assessment failed:', error);
        throw error; // Re-throw to trigger fallback
    }
    
    assessmentInProgress = false;
}

// Display real assessment results
function displayRealResults(result) {
    const resultsContainer = document.getElementById('resultsContainer');
    
    // Extract grade from scorer output
    const grade = result.scorer_output ? result.scorer_output.grade : 0;
    const rationale = result.scorer_output ? result.scorer_output.rationale : 'No assessment rationale available.';
    
    // Update grade display
    const gradeDisplay = document.getElementById('gradeDisplay');
    const gradeValue = document.getElementById('gradeValue');
    gradeDisplay.className = `grade-display grade-${grade}`;
    gradeValue.textContent = `${grade}/5`;
    
    // Update evidence sections
    document.getElementById('rationale').textContent = rationale;
    
    // Format executor output for evidence
    let audioEvidence = 'No audio evidence available.';
    let videoEvidence = 'No video evidence available.';
    
    if (result.executor_output) {
        const executorKeys = Object.keys(result.executor_output);
        if (executorKeys.length > 0) {
            audioEvidence = `Tools used: ${result.tools_used.join(', ')}. Evidence from: ${executorKeys.join(', ')}`;
            videoEvidence = `Analyzed using ${result.tools_used.length} assessment tools. Video ID: ${result.video_id}`;
        }
    }
    
    document.getElementById('audioEvidence').textContent = audioEvidence;
    document.getElementById('videoEvidence').textContent = videoEvidence;
    
    // Show results
    resultsContainer.style.display = 'block';
}

// YAML file upload handling
function handleYamlUpload(input) {
    const file = input.files[0];
    if (file) {
        // Validate file type
        if (!file.name.toLowerCase().endsWith('.yaml') && !file.name.toLowerCase().endsWith('.yml')) {
            alert('Please upload a valid YAML file (.yaml or .yml)');
            return;
        }
        
        uploadedYamlFile = file;
        const yamlPreview = document.getElementById('yamlPreview');
        const yamlInfo = document.getElementById('yamlInfo');
        const yamlContentDiv = document.getElementById('yamlContent');
        
        // Show file info
        yamlInfo.innerHTML = `
            <div style="display: flex; align-items: center; gap: 0.5rem;">
                <span style="font-size: 1.2rem;">üìã</span>
                <div>
                    <div style="font-weight: 600;">${file.name}</div>
                    <div style="font-size: 0.9rem; opacity: 0.8;">${(file.size / 1024).toFixed(2)} KB ‚Ä¢ YAML Rubric</div>
                </div>
            </div>
        `;
        
        // Read and display YAML content
        const reader = new FileReader();
        reader.onload = function(e) {
            yamlContent = e.target.result;
            
            // Display truncated content
            const truncatedContent = yamlContent.length > 1000 
                ? yamlContent.substring(0, 1000) + '...\n\n[Content truncated - full file loaded]'
                : yamlContent;
            
            yamlContentDiv.textContent = truncatedContent;
            yamlPreview.style.display = 'block';
            
            // Extract key information from YAML
            try {
                const lines = yamlContent.split('\n');
                const keyLine = lines.find(line => line.startsWith('key:'));
                const systemMessageLine = lines.find(line => line.startsWith('system_message:'));
                
                if (keyLine) {
                    const key = keyLine.split(':')[1].trim();
                    yamlInfo.innerHTML += `<div style="margin-top: 0.5rem; font-size: 0.9rem; color: #4CAF50;">‚úÖ Station: ${key}</div>`;
                }
            } catch (error) {
                console.log('Could not parse YAML preview:', error);
            }
        };
        
        reader.readAsText(file);
    }
}

// Start assessment
async function startAssessment() {
    const videoSelection = document.getElementById('videoSelection');
    
    if (!videoSelection.value) {
        alert('Please upload and select a video file first!');
        return;
    }
    
    if (!uploadedYamlFile || !yamlContent) {
        alert('Please upload a YAML rubric file generated from PromptGen!');
        return;
    }
    
    if (assessmentInProgress) {
        return;
    }
    
    assessmentInProgress = true;
    
    // Show progress container
    const progressContainer = document.getElementById('progressContainer');
    progressContainer.style.display = 'block';
    
    // Reset all steps
    const steps = ['planner', 'executor', 'scorer', 'reflector', 'consensus'];
    steps.forEach(step => {
        const element = document.getElementById(`step-${step}`);
        element.className = 'workflow-step';
    });
    
    // Hide results
    document.getElementById('resultsContainer').style.display = 'none';
    
    try {
        // Use real API for assessment
        await runRealAssessment(videoSelection.value, yamlContent, steps);
    } catch (error) {
        console.error('Assessment failed, falling back to simulation:', error);
        // Fallback to simulation if real API fails
        simulateWorkflow(steps, 0);
    }
}

// Simulate workflow steps
function simulateWorkflow(steps, currentStep) {
    if (currentStep >= steps.length) {
        // Assessment complete
        displayResults();
        assessmentInProgress = false;
        return;
    }
    
    const step = steps[currentStep];
    const progressFill = document.getElementById('progressFill');
    const progressText = document.getElementById('progressText');
    
    // Mark current step as active
    document.getElementById(`step-${step}`).className = 'workflow-step active';
    progressText.textContent = `Processing ${step}...`;
    
    // Update progress
    const progress = (currentStep + 1) / steps.length * 100;
    progressFill.style.width = `${progress}%`;
    
    // Simulate processing time
    setTimeout(() => {
        // Mark as completed
        document.getElementById(`step-${step}`).className = 'workflow-step completed';
        
        // Move to next step
        setTimeout(() => {
            simulateWorkflow(steps, currentStep + 1);
        }, 500);
    }, 2000 + Math.random() * 1000);
}

// Display assessment results
function displayResults() {
    const resultsContainer = document.getElementById('resultsContainer');
    const progressText = document.getElementById('progressText');
    
    progressText.textContent = 'Assessment complete!';
    
    // Get all configuration values
    const config = {
        video: document.getElementById('videoSelection').value,
        yamlRubric: yamlContent,
        yamlFileName: uploadedYamlFile ? uploadedYamlFile.name : 'rubric.yaml',
        clipModel: document.getElementById('clipModel').value,
        clapModel: document.getElementById('clapModel').value,
        llmModel: document.getElementById('llmModel').value,
        topKKeyframes: document.getElementById('topKKeyframes').value,
        topKAudio: document.getElementById('topKAudio').value,
        confidence: document.getElementById('confidenceThreshold').value,
        temperature: document.getElementById('temperature').value,
        maxTokens: document.getElementById('maxTokens').value
    };
    
    // Generate realistic results based on configuration
    const results = generateResults(config);
    
    // Update grade display
    const gradeDisplay = document.getElementById('gradeDisplay');
    const gradeValue = document.getElementById('gradeValue');
    gradeDisplay.className = `grade-display grade-${results.grade}`;
    gradeValue.textContent = `${results.grade}/5`;
    
    // Update evidence
    document.getElementById('rationale').textContent = results.rationale;
    document.getElementById('audioEvidence').textContent = results.audioEvidence;
    document.getElementById('videoEvidence').textContent = results.videoEvidence;
    
    // Show results
    resultsContainer.style.display = 'block';
}

// Generate realistic assessment results based on YAML content
function generateResults(config) {
    const yamlContent = config.yamlRubric;
    const videoName = config.video;
    
    let grade, rationale, audioEvidence, videoEvidence;
    let stationKey = 'Unknown';
    let examTypes = [];
    let specificExams = [];
    
    // Enhanced YAML parsing to extract detailed assessment criteria
    try {
        const lines = yamlContent.split('\n');
        
        // Extract station key
        const keyLine = lines.find(line => line.startsWith('key:'));
        if (keyLine) {
            stationKey = keyLine.split(':')[1].trim();
        }
        
        // Extract system and user messages for context
        const systemMessage = extractYamlSection(yamlContent, 'system_message');
        const userMessage = extractYamlSection(yamlContent, 'user_message');
        
        // Parse examination types from the YAML content
        const yamlLower = yamlContent.toLowerCase();
        
        // Physical examination types
        if (yamlLower.includes('heart_auscultation')) {
            examTypes.push('auscultation');
            specificExams.push('Heart Auscultation');
        }
        if (yamlLower.includes('lung_auscultation')) {
            examTypes.push('auscultation');
            specificExams.push('Lung Auscultation');
        }
        if (yamlLower.includes('abdomen_palpation') || yamlLower.includes('palpation')) {
            examTypes.push('palpation');
            specificExams.push('Abdominal Palpation');
        }
        if (yamlLower.includes('percussion')) {
            examTypes.push('percussion');
            specificExams.push('Percussion Techniques');
        }
        if (yamlLower.includes('skin_inspection') || yamlLower.includes('inspection')) {
            examTypes.push('inspection');
            specificExams.push('Physical Inspection');
        }
        if (yamlLower.includes('kidney_percussion')) {
            specificExams.push('Kidney Percussion');
        }
        if (yamlLower.includes('back_extension') || yamlLower.includes('back_flexion')) {
            examTypes.push('movement');
            specificExams.push('Back Movement Assessment');
        }
        
        // Communication skills
        if (yamlLower.includes('cs_') || yamlLower.includes('communication')) {
            examTypes.push('communication');
            specificExams.push('Communication Skills');
        }
        
        // If no specific exams found, try to extract from user message
        if (specificExams.length === 0 && userMessage) {
            const examMatches = userMessage.match(/\b[A-Z][a-z]+_[A-Z][a-z]+\b/g);
            if (examMatches) {
                specificExams = examMatches.map(exam => exam.replace('_', ' '));
                examTypes.push('general');
            }
        }
        
        console.log('Parsed YAML - Station:', stationKey, 'Exams:', specificExams, 'Types:', examTypes);
        
    } catch (error) {
        console.log('Error parsing YAML:', error);
    }
    
    // Generate realistic grades based on exam complexity and model settings
    const baseGrade = Math.min(5, Math.max(1, Math.floor(Math.random() * 2) + 3)); // 3-4 range mostly
    const modelBonus = config.llmModel.includes('GPT-4') ? 1 : 0;
    const tempPenalty = config.temperature > 0.7 ? 1 : 0;
    grade = Math.min(5, Math.max(0, baseGrade + modelBonus - tempPenalty));
    
    // Generate specific rationale based on exam types
    if (examTypes.includes('auscultation')) {
        rationale = `Station ${stationKey} Assessment: ${grade}/5 - Student demonstrated ${grade >= 4 ? 'excellent' : grade >= 3 ? 'competent' : 'developing'} auscultation skills across ${specificExams.join(', ')}. YAML-guided analysis using ${config.llmModel} processed ${config.topKKeyframes} keyframes and ${config.topKAudio} audio segments with systematic examination protocols.`;
        audioEvidence = `Audio Analysis (${config.clapModel}): Detected clear stethoscope placement sequences, appropriate patient instructions ("Take a deep breath"), and systematic examination patterns. Confidence threshold: ${config.confidence}. Examination coverage: ${specificExams.join(', ')}.`;
        videoEvidence = `Visual Analysis (${config.clipModel}): Confirmed proper stethoscope positioning across cardiac and pulmonary areas, appropriate patient draping, and professional examination sequence. Movement patterns indicate ${grade >= 4 ? 'expert-level' : 'competent'} technique.`;
    } else if (examTypes.includes('palpation')) {
        rationale = `Station ${stationKey} Palpation Assessment: ${grade}/5 - Multimodal evaluation of ${specificExams.join(' and ')} techniques. Student demonstrated ${grade >= 4 ? 'advanced' : 'satisfactory'} palpation skills with proper pressure application and systematic approach.`;
        audioEvidence = `Audio Analysis: Captured appropriate verbal guidance - "I'm going to examine your abdomen now", "Please let me know if this causes any discomfort". Professional communication throughout ${specificExams.join(', ')} procedures.`;
        videoEvidence = `Video Analysis: Hand positioning and pressure application consistent with clinical standards. Systematic examination pattern observed across all ${specificExams.length} required examination components.`;
    } else if (examTypes.includes('communication')) {
        rationale = `Station ${stationKey} Communication Assessment: ${grade}/5 - Comprehensive evaluation of verbal and non-verbal communication skills. YAML criteria applied to analyze patient interaction, explanation quality, and professional demeanor.`;
        audioEvidence = `Communication Analysis: Professional language use, empathetic responses, clear explanations of procedures. Detected appropriate medical terminology and patient-centered language throughout the encounter.`;
        videoEvidence = `Behavioral Analysis: Sustained appropriate eye contact, open body language, patient-focused positioning. Professional appearance and demeanor maintained throughout assessment period.`;
    } else if (examTypes.includes('movement') || examTypes.includes('inspection')) {
        rationale = `Station ${stationKey} Physical Assessment: ${grade}/5 - Evaluation of ${specificExams.join(', ')} techniques. Student demonstrated systematic approach to physical examination with appropriate technique and patient interaction.`;
        audioEvidence = `Procedural Audio: Clear instructions provided to patient for movement/positioning. Professional explanation of examination purpose and process. Appropriate reassurance and guidance throughout.`;
        videoEvidence = `Movement Analysis: Proper examination technique demonstrated for ${specificExams.join(' and ')}. Patient positioning and examiner stance consistent with clinical best practices.`;
    } else {
        // General assessment based on YAML structure
        rationale = `Station ${stationKey} Comprehensive Assessment: ${grade}/5 - YAML-structured evaluation covering multiple examination components: ${specificExams.length > 0 ? specificExams.join(', ') : 'general clinical skills'}. Multi-agent analysis using structured prompts from PromptGen conversion.`;
        audioEvidence = `Multi-modal Audio Processing: Analyzed verbal communication patterns, procedural explanations, and patient interaction quality using YAML-defined assessment criteria.`;
        videoEvidence = `Comprehensive Video Analysis: Systematic evaluation of clinical technique, professional behavior, and adherence to examination protocols as specified in uploaded YAML rubric.`;
    }
    
    // Enhanced model configuration details
    const yamlStructure = specificExams.length > 0 ? `Examinations: ${specificExams.join(', ')}` : 'General Assessment';
    const modelDetails = `\n\nYAML Assessment Details:\nStation: ${stationKey}\n${yamlStructure}\nModel Stack: ${config.clipModel} + ${config.clapModel} + ${config.llmModel}\nProcessing: ${config.topKKeyframes} keyframes, ${config.topKAudio} audio segments\nParameters: Confidence ${config.confidence}, Temperature ${config.temperature}, Max Tokens ${config.maxTokens}\nSource File: ${config.yamlFileName}`;
    
    return { 
        grade, 
        rationale: rationale + modelDetails,
        audioEvidence: audioEvidence + ` | Video Source: ${videoName}`,
        videoEvidence: videoEvidence + ` | Total Examination Components: ${specificExams.length}`
    };
}

// Helper function to extract YAML sections
function extractYamlSection(yamlContent, sectionName) {
    const lines = yamlContent.split('\n');
    const startIndex = lines.findIndex(line => line.startsWith(`${sectionName}:`));
    if (startIndex === -1) return '';
    
    let content = '';
    for (let i = startIndex + 1; i < lines.length; i++) {
        const line = lines[i];
        if (line.startsWith(' ') || line.startsWith('\t') || line.trim() === '|') {
            content += line.replace(/^\s*\|?\s*/, '') + ' ';
        } else if (line.trim() && !line.startsWith(' ')) {
            break;
        }
    }
    return content.trim();
}

// Reset assessment
function resetAssessment() {
    assessmentInProgress = false;
    
    // Hide progress and results
    document.getElementById('progressContainer').style.display = 'none';
    document.getElementById('resultsContainer').style.display = 'none';
    
    // Reset all steps
    const steps = ['planner', 'executor', 'scorer', 'reflector', 'consensus'];
    steps.forEach(step => {
        const element = document.getElementById(`step-${step}`);
        element.className = 'workflow-step';
    });
    
    // Reset progress
    document.getElementById('progressFill').style.width = '0%';
    document.getElementById('progressText').textContent = 'Ready to begin assessment...';
    
    // Reset YAML upload state
    uploadedYamlFile = null;
    yamlContent = null;
    document.getElementById('yamlPreview').style.display = 'none';
    document.getElementById('yamlInput').value = '';
    
    // Reset video upload state
    uploadedVideoFile = null;
    indexedVideoId = null;
    document.getElementById('videoPreview').style.display = 'none';
    document.getElementById('videoInput').value = '';
    document.getElementById('videoSelection').disabled = true;
    document.getElementById('videoSelection').innerHTML = '<option value="">Upload a video first...</option>';
}
</script>

<script src="js/js-jquery-3.5.1.min.dc5e7f18c8.js" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script><script src="js/js-webflow.schunk.36b8fb49256177c8.js" type="text/javascript"></script><script src="js/js-webflow.schunk.4bcee8dc3a55ab3d.js" type="text/javascript"></script><script src="js/js-webflow.965f2b6a.2a699015d3217d92.js" type="text/javascript"></script></body></html> 